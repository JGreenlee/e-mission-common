{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import matplotlib.colors as mcolors\n",
    "from shapely.geometry import Polygon\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "\n",
    "# Directory to store shapefiles\n",
    "shapefile_dir = \"shapefile\"\n",
    "os.makedirs(shapefile_dir, exist_ok=True)\n",
    "\n",
    "# URLs for individual files in the GitHub repository and UACE Census TIGER data\n",
    "natural_earth_files = {\n",
    "    \"ne_10m_admin_0_countries\": [\n",
    "        \"https://raw.githubusercontent.com/nvkelso/natural-earth-vector/master/10m_cultural/ne_10m_admin_0_countries.shp\",\n",
    "        \"https://raw.githubusercontent.com/nvkelso/natural-earth-vector/master/10m_cultural/ne_10m_admin_0_countries.shx\",\n",
    "        \"https://raw.githubusercontent.com/nvkelso/natural-earth-vector/master/10m_cultural/ne_10m_admin_0_countries.dbf\",\n",
    "        \"https://raw.githubusercontent.com/nvkelso/natural-earth-vector/master/10m_cultural/ne_10m_admin_0_countries.prj\",\n",
    "    ],\n",
    "    \"ne_10m_admin_1_states_provinces\": [\n",
    "        \"https://raw.githubusercontent.com/nvkelso/natural-earth-vector/master/10m_cultural/ne_10m_admin_1_states_provinces.shp\",\n",
    "        \"https://raw.githubusercontent.com/nvkelso/natural-earth-vector/master/10m_cultural/ne_10m_admin_1_states_provinces.shx\",\n",
    "        \"https://raw.githubusercontent.com/nvkelso/natural-earth-vector/master/10m_cultural/ne_10m_admin_1_states_provinces.dbf\",\n",
    "        \"https://raw.githubusercontent.com/nvkelso/natural-earth-vector/master/10m_cultural/ne_10m_admin_1_states_provinces.prj\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "uace_url = \"https://www2.census.gov/geo/tiger/TIGER2024/UAC20/tl_2024_us_uac20.zip\"\n",
    "uace_zip_path = os.path.join(shapefile_dir, \"tl_2024_us_uac20.zip\")\n",
    "\n",
    "# Function to download each file\n",
    "def download_files(file_urls):\n",
    "    for url in file_urls:\n",
    "        filename = os.path.join(shapefile_dir, url.split('/')[-1])\n",
    "        if not os.path.exists(filename):\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Downloaded {filename}.\")\n",
    "        else:\n",
    "            print(f\"{filename} already exists.\")\n",
    "\n",
    "# Function to download and extract the UACE ZIP file\n",
    "def download_and_extract_uace(url, zip_path):\n",
    "    if not os.path.exists(zip_path):\n",
    "        print(f\"Downloading UACE data from {url}...\")\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        with open(zip_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Downloaded {zip_path}.\")\n",
    "    \n",
    "    # Extract UACE shapefile\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(shapefile_dir)\n",
    "    print(f\"Extracted UACE shapefiles to {shapefile_dir}.\")\n",
    "\n",
    "# Download Natural Earth files\n",
    "for file_urls in natural_earth_files.values():\n",
    "    download_files(file_urls)\n",
    "\n",
    "# Download and extract UACE shapefile\n",
    "download_and_extract_uace(uace_url, uace_zip_path)\n",
    "\n",
    "# Load the shapefiles using the original filenames\n",
    "world = gpd.read_file(os.path.join(shapefile_dir, \"ne_10m_admin_0_countries.shp\"))\n",
    "states_provinces = gpd.read_file(os.path.join(shapefile_dir, \"ne_10m_admin_1_states_provinces.shp\"))\n",
    "uace_shapefile = gpd.read_file(os.path.join(shapefile_dir, \"tl_2024_us_uac20.shp\"))\n",
    "\n",
    "# Filter for the United States in the world shapefile\n",
    "us_boundary = world[world['NAME'] == 'United States of America']\n",
    "\n",
    "\n",
    "def process_state_deltas(state_name, year_ranges, mode_type, metric_column):\n",
    "    # Determine the modes based on mode_type\n",
    "    if mode_type == \"bus\":\n",
    "        modes = ['MB', 'RB', 'CB']\n",
    "        title_suffix = \"Bus Modes\"\n",
    "    elif mode_type == \"train\":\n",
    "        modes = ['LR', 'HR', 'YR', 'CR']\n",
    "        title_suffix = \"Train Modes\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode_type. Use 'bus' or 'train'.\")\n",
    "\n",
    "    # Define the column title for plot labels based on the metric\n",
    "    # CHANGE TO WH/KM: If we're dealing with \"All Fuels (Wh/pkm),\" rename to Wh/km\n",
    "    if metric_column == \"All Fuels (Wh/pkm)\":\n",
    "        metric_title = \"Fuel Efficiency (Wh/km)\"\n",
    "    elif metric_column == \"Average Passengers\":\n",
    "        metric_title = \"Average Passengers\"\n",
    "    else:\n",
    "        metric_title = metric_column\n",
    "\n",
    "    def load_year_data(year):\n",
    "        json_file = f\"../src/emcommon/resources/ntd{year}_intensities.json\"\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        df = pd.DataFrame(data['records'])\n",
    "\n",
    "        mode_df = df[df['Mode'].isin(modes)]\n",
    "\n",
    "        mode_df[metric_column] = pd.to_numeric(mode_df[metric_column], errors='coerce')\n",
    "        mode_df['Unlinked Passenger Trips'] = pd.to_numeric(mode_df['Unlinked Passenger Trips'], errors='coerce')\n",
    "        mode_df['Average Passengers'] = pd.to_numeric(mode_df['Average Passengers'], errors='coerce')\n",
    "        mode_df = mode_df.dropna(subset=[metric_column, 'Unlinked Passenger Trips', 'UACE Code', 'Average Passengers'])\n",
    "\n",
    "        # CHANGE TO WH/KM: Convert Wh/pkm to Wh/km by multiplying by Average Passengers\n",
    "        if metric_column == \"All Fuels (Wh/pkm)\":\n",
    "            mode_df[metric_column] = mode_df[metric_column] * mode_df[\"Average Passengers\"]\n",
    "\n",
    "        mode_df['UACE Code'] = mode_df['UACE Code'].astype(str).str.zfill(5)\n",
    "        grouped = mode_df.groupby('UACE Code').apply(\n",
    "            lambda x: pd.Series({\n",
    "                f'Weighted {metric_column}': (x[metric_column] * x['Unlinked Passenger Trips']).sum() / x['Unlinked Passenger Trips'].sum(),\n",
    "            })\n",
    "        ).reset_index()\n",
    "\n",
    "        return grouped\n",
    "\n",
    "    # Determine the number of plots based on the number of year ranges\n",
    "    num_plots = len(year_ranges)\n",
    "    figsize = (9 * num_plots, 8)  # Adjust the figure size based on the number of plots\n",
    "\n",
    "    # Create a figure with the appropriate number of subplots\n",
    "    fig, axs = plt.subplots(1, num_plots, figsize=figsize, constrained_layout=True)\n",
    "    if num_plots == 1:\n",
    "        axs = [axs]  # Ensure axs is always a list for consistency\n",
    "\n",
    "    fig.subplots_adjust(top=0.88)  # Add space above subplots\n",
    "    titley = 0.93\n",
    "    if state_name == \"North Carolina\":\n",
    "        titley = 0.76\n",
    "    elif state_name == \"Massachusetts\":\n",
    "        titley = 0.82\n",
    "    elif state_name == \"Colorado\":\n",
    "        titley = 0.86\n",
    "    fig.suptitle(f\"{state_name} {mode_type.title()} - {metric_title}\", fontsize=20, y=titley)\n",
    "\n",
    "    # Define color normalization and color map based on metric and mode type\n",
    "    if metric_column == \"All Fuels (Wh/pkm)\":\n",
    "        norm = mcolors.Normalize(vmin=-800, vmax=800)\n",
    "    elif metric_column == \"Average Passengers\":\n",
    "        if mode_type == \"bus\":\n",
    "            norm = mcolors.Normalize(vmin=-4, vmax=4)\n",
    "        elif mode_type == \"train\":\n",
    "            norm = mcolors.Normalize(vmin=-40, vmax=40)\n",
    "    else:\n",
    "        norm = mcolors.Normalize(vmin=-4, vmax=4)  # Default case if needed\n",
    "\n",
    "    if metric_column == \"All Fuels (Wh/pkm)\":\n",
    "        cmap = 'RdYlGn_r'\n",
    "    else:\n",
    "        cmap = 'RdYlGn'\n",
    "\n",
    "    # Filter for the specified state\n",
    "    state = states_provinces[states_provinces['name'] == state_name]\n",
    "    state_boundary = state.unary_union  # Get the boundary as a single geometry\n",
    "\n",
    "    for ax, (year_start, year_end) in zip(axs, year_ranges):\n",
    "        # Load data for both years\n",
    "        data_start = load_year_data(year_start)\n",
    "        data_end = load_year_data(year_end)\n",
    "\n",
    "        # Merge data for both years to calculate the delta\n",
    "        data_delta = data_start.merge(data_end, on=\"UACE Code\", suffixes=(f'_{year_start}', f'_{year_end}'))\n",
    "        data_delta[f'Delta {metric_column}'] = data_delta[f'Weighted {metric_column}_{year_end}'] - data_delta[f'Weighted {metric_column}_{year_start}']\n",
    "\n",
    "        # Merge with UACE shapefile for spatial plotting\n",
    "        uace_shapefile['GEOID20'] = uace_shapefile['GEOID20'].astype(str).str.zfill(5)\n",
    "        merged_gdf = uace_shapefile.merge(data_delta, left_on='GEOID20', right_on='UACE Code', how='inner')\n",
    "\n",
    "        # Identify UACE regions with data and without data (no data)\n",
    "        uace_with_data = merged_gdf.copy()\n",
    "        uace_no_data = uace_shapefile[~uace_shapefile['GEOID20'].isin(uace_with_data['GEOID20'])]\n",
    "\n",
    "        # Perform spatial intersection to clip UACE regions to the state boundary\n",
    "        clipped_with_data = gpd.overlay(uace_with_data, gpd.GeoDataFrame(geometry=[state_boundary], crs=uace_with_data.crs), how='intersection')\n",
    "        clipped_no_data = gpd.overlay(uace_no_data, gpd.GeoDataFrame(geometry=[state_boundary], crs=uace_no_data.crs), how='intersection')\n",
    "\n",
    "        # Plot the delta values for the specified time range\n",
    "        clipped_with_data.plot(\n",
    "            ax=ax,\n",
    "            column=f'Delta {metric_column}',\n",
    "            cmap=cmap,\n",
    "            legend=False,\n",
    "            edgecolor='grey',\n",
    "            linewidth=0.5,\n",
    "            norm=norm,\n",
    "        )\n",
    "\n",
    "        # Plot the UACE regions with no data using hatch pattern\n",
    "        clipped_no_data.plot(\n",
    "            ax=ax,\n",
    "            color=\"none\",\n",
    "            edgecolor=\"grey\",\n",
    "            hatch=\"////////\",\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "\n",
    "        # Overlay state boundary\n",
    "        state.plot(ax=ax, color=\"none\", edgecolor=\"black\", linewidth=1.5)\n",
    "\n",
    "        # Set title and bounds for each subplot\n",
    "        ax.set_title(f\"{year_start}-{year_end} Delta\", fontsize=16)\n",
    "        if state_name == \"Massachusetts\":\n",
    "            ax.set_xlim([-73.5, -69.9])\n",
    "            ax.set_ylim([41.2, 42.9])\n",
    "        elif state_name == \"Colorado\":\n",
    "            ax.set_xlim([-109.1, -102.0])\n",
    "            ax.set_ylim([36.9, 41.0])\n",
    "        elif state_name == \"North Carolina\":\n",
    "            ax.set_xlim([-84.3, -75.5])\n",
    "            ax.set_ylim([33.8, 36.6])\n",
    "\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "    # Add a single colorbar for the entire figure\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm._A = []  # Dummy array for colorbar\n",
    "    cbar = fig.colorbar(sm, ax=axs, orientation='vertical', fraction=0.02, pad=0.04, shrink=0.5)\n",
    "    cbar.set_label(f\"Delta {metric_title}\")\n",
    "\n",
    "    # Create a custom legend entry for \"No Data\" with hatching\n",
    "    no_data_patch = mpatches.Patch(facecolor=\"none\", edgecolor=\"grey\", hatch=\"////////\", label=\"No Data\")\n",
    "    if state_name == \"North Carolina\":\n",
    "        patch_y = 0.25\n",
    "    else:\n",
    "        patch_y = 0.14\n",
    "    fig.legend(handles=[no_data_patch], loc=\"lower right\", bbox_to_anchor=(0.93, patch_y), fontsize=12)\n",
    "\n",
    "    # Save and display the combined figure for the state and mode type\n",
    "    year_range_str = \"-\".join([f\"{start}_{end}\" for start, end in year_ranges])\n",
    "    plt.savefig(f\"delta_{metric_column.replace(' ', '_').replace('/', '_').replace('(', '').replace(')', '').lower()}_{title_suffix.replace(' ', '_').lower()}_{state_name.replace(' ', '_').lower()}_{year_range_str}.pdf\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Specify states and year ranges for deltas\n",
    "states = [\"Massachusetts\", \"Colorado\", \"North Carolina\"]\n",
    "# year_ranges = [(2018, 2020), (2020, 2022)]\n",
    "year_ranges = [(2018, 2022)]\n",
    "\n",
    "# Generate delta plots for each state and mode type for both metrics\n",
    "# for mode_type in [\"bus\", \"train\"]:\n",
    "for mode_type in [\"bus\"]:\n",
    "    for state in states:\n",
    "        process_state_deltas(state, year_ranges, mode_type, \"All Fuels (Wh/pkm)\")  # For fuel efficiency\n",
    "        process_state_deltas(state, year_ranges, mode_type, \"Average Passengers\")  # For average occupancy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_national_and_uace_average_passengers(years, uace=None, mode_type=\"bus\"):\n",
    "    \"\"\"\n",
    "    Calculate the weighted national average passengers and for a specific UACE.\n",
    "    \n",
    "    Parameters:\n",
    "        years (list): List of years to process.\n",
    "        uace (str): UACE code to filter on. If None, only calculates national average.\n",
    "        mode_type (str): Mode type to process (default: 'bus').\n",
    "    \"\"\"\n",
    "    # Define bus modes\n",
    "    if mode_type == \"bus\":\n",
    "        modes = ['MB', 'RB', 'CB']  # Bus modes\n",
    "    else:\n",
    "        raise ValueError(\"Currently only 'bus' mode is supported.\")\n",
    "\n",
    "    # Directory containing the JSON files\n",
    "    json_dir = \"../src/emcommon/resources/\"\n",
    "\n",
    "    # Loop through each year and calculate averages\n",
    "    for year in years:\n",
    "        json_file = os.path.join(json_dir, f\"ntd{year}_intensities.json\")\n",
    "        if not os.path.exists(json_file):\n",
    "            print(f\"File for year {year} not found: {json_file}\")\n",
    "            continue\n",
    "\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(data['records'])\n",
    "\n",
    "        # Filter for bus modes\n",
    "        mode_df = df[df['Mode'].isin(modes)]\n",
    "\n",
    "        # Ensure numeric columns\n",
    "        mode_df['Average Passengers'] = pd.to_numeric(mode_df['Average Passengers'], errors='coerce')\n",
    "        mode_df['Unlinked Passenger Trips'] = pd.to_numeric(mode_df['Unlinked Passenger Trips'], errors='coerce')\n",
    "\n",
    "        # Drop rows with missing values\n",
    "        mode_df = mode_df.dropna(subset=['Average Passengers', 'Unlinked Passenger Trips'])\n",
    "\n",
    "        # Calculate the weighted national average for passengers\n",
    "        total_passenger_trips = mode_df['Unlinked Passenger Trips'].sum()\n",
    "        weighted_avg_passengers = (mode_df['Average Passengers'] * mode_df['Unlinked Passenger Trips']).sum() / total_passenger_trips\n",
    "        print(f\"Year {year}: Weighted National Average Passengers for Bus = {weighted_avg_passengers:.2f}\")\n",
    "\n",
    "        # If UACE is provided, filter and calculate for specific UACE\n",
    "        if uace:\n",
    "            uace_df = mode_df[mode_df['UACE Code'] == str(uace)]\n",
    "\n",
    "            if not uace_df.empty:\n",
    "                total_uace_trips = uace_df['Unlinked Passenger Trips'].sum()\n",
    "                weighted_uace_avg_passengers = (uace_df['Average Passengers'] * uace_df['Unlinked Passenger Trips']).sum() / total_uace_trips\n",
    "                print(f\"Year {year}, UACE {uace}: Weighted Average Passengers for Bus = {weighted_uace_avg_passengers:.2f}\")\n",
    "            else:\n",
    "                print(f\"Year {year}: No data for UACE {uace}\")\n",
    "\n",
    "# Define the years to process\n",
    "years = [2018, 2019, 2020, 2021, 2022]\n",
    "\n",
    "# Call the function with UACE filtering\n",
    "calculate_national_and_uace_average_passengers(years, uace=\"23527\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
